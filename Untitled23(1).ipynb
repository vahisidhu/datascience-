{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6aae927",
   "metadata": {},
   "source": [
    "# WEB SCRAPING-ASSIGNMENT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ef3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    ". Scrape the details of most viewed videos on YouTube from Wikipedia. Url\n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A)\n",
    "Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c820c6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m By\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "# Set up the Selenium WebDriver (make sure the path to your ChromeDriver is correct)\n",
    "driver = webdriver.Chrome(executable_path='/path/to/chromedriver')\n",
    "\n",
    "# Open the Wikipedia page\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "\n",
    "# Allow the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Find the table containing the most-viewed YouTube videos\n",
    "table = driver.find_element(By.CLASS_NAME, 'wikitable')\n",
    "\n",
    "# Extract the rows from the table\n",
    "rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "# List to hold the video details\n",
    "video_details = []\n",
    "\n",
    "# Loop through the rows to extract details\n",
    "for row in rows[1:]:  # Skip the header row\n",
    "    cols = row.find_elements(By.TAG_NAME, 'td')\n",
    "    rank = cols[0].text.strip()\n",
    "    name = cols[1].text.strip().split('\"')[1]  # Extracting the name within quotes\n",
    "    artist = cols[2].text.strip()\n",
    "    upload_date = cols[3].text.strip()\n",
    "    views = cols[4].text.strip()\n",
    "    video_details.append([rank, name, artist, upload_date, views])\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Print the details\n",
    "for detail in video_details:\n",
    "    print(detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a09a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scrape the details team Indiaâ€™s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "015c86ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m By\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Set up the Selenium WebDriver (ensure the path to your ChromeDriver is correct)\n",
    "driver = webdriver.Chrome(executable_path='/path/to/chromedriver')\n",
    "\n",
    "# Open the BCCI website\n",
    "driver.get('https://www.bcci.tv/')\n",
    "\n",
    "# Allow the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Navigate to the fixtures section\n",
    "fixtures_section = driver.find_element(By.XPATH, '//a[@href=\"/fixtures\"]').click()\n",
    "\n",
    "# Allow the fixtures page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Find the fixtures elements\n",
    "fixtures = driver.find_elements(By.CLASS_NAME, 'js-match')\n",
    "\n",
    "# List to hold the fixture details\n",
    "fixture_details = []\n",
    "\n",
    "# Loop through the fixtures to extract details\n",
    "for fixture in fixtures:\n",
    "    series = fixture.find_element(By.CLASS_NAME, 'fixture__name').text\n",
    "    place = fixture.find_element(By.CLASS_NAME, 'fixture__place').text\n",
    "    date = fixture.find_element(By.CLASS_NAME, 'fixture__date').text\n",
    "    time_ = fixture.find_element(By.CLASS_NAME, 'fixture__time').text\n",
    "    fixture_details.append([series, place, date, time_])\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Print the details\n",
    "for detail in fixture_details:\n",
    "    print(detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c9a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "456b887c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m By\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Set up the Selenium WebDriver\n",
    "driver = webdriver.Chrome(executable_path='/path/to/chromedriver')\n",
    "\n",
    "# Open the Statistics Times website\n",
    "driver.get('http://statisticstimes.com/')\n",
    "\n",
    "# Allow the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Navigate to the GDP section\n",
    "gdp_section = driver.find_element(By.LINK_TEXT, 'India').click()\n",
    "time.sleep(2)\n",
    "gdp_section = driver.find_element(By.LINK_TEXT, 'GSDP of Indian states').click()\n",
    "\n",
    "# Allow the GDP page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Find the table containing the state-wise GDP details\n",
    "table = driver.find_element(By.CLASS_NAME, 'display')\n",
    "\n",
    "# Extract the table rows\n",
    "rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "# List to hold the GDP details\n",
    "gdp_details = []\n",
    "\n",
    "# Loop through the rows to extract details\n",
    "for row in rows[1:]:  # Skip the header row\n",
    "    cols = row.find_elements(By.TAG_NAME, 'td')\n",
    "    rank = cols[0].text.strip()\n",
    "    state = cols[1].text.strip()\n",
    "    gsdp_18_19 = cols[2].text.strip()\n",
    "    gsdp_19_20 = cols[3].text.strip()\n",
    "    share_18_19 = cols[4].text.strip()\n",
    "    gdp_billion = cols[5].text.strip()\n",
    "    gdp_details.append([rank, state, gsdp_18_19, gsdp_19_20, share_18_19, gdp_billion])\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Print the details\n",
    "for detail in gdp_details:\n",
    "    print(detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568b0568",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71369b0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m By\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Set up the Selenium WebDriver\n",
    "driver = webdriver.Chrome(executable_path='/path/to/chromedriver')\n",
    "\n",
    "# Open the GitHub trending page\n",
    "driver.get('https://github.com/trending')\n",
    "\n",
    "# Allow the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Find the repository elements\n",
    "repositories = driver.find_elements(By.CLASS_NAME, 'Box-row')\n",
    "\n",
    "# List to hold the repository details\n",
    "repo_details = []\n",
    "\n",
    "# Loop through the repositories to extract details\n",
    "for repo in repositories:\n",
    "    title = repo.find_element(By.TAG_NAME, 'h1').text.strip()\n",
    "    description = repo.find_element(By.TAG_NAME, 'p').text.strip() if repo.find_element(By.TAG_NAME, 'p') else 'No description'\n",
    "    contributors = repo.find_elements(By.CSS_SELECTOR, 'a[data-hovercard-type=\"user\"]')\n",
    "    contributors_count = len(contributors)\n",
    "    language = repo.find_element(By.XPATH, './/span[@itemprop=\"programmingLanguage\"]').text.strip() if repo.find_element(By.XPATH, './/span[@itemprop=\"programmingLanguage\"]') else 'No language'\n",
    "    repo_details.append([title, description, contributors_count, language])\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Print the details\n",
    "for detail in repo_details:\n",
    "    print(detail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d804485",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the\n",
    "following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29e97d12",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m By\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Set up the Selenium WebDriver\n",
    "driver = webdriver.Chrome(executable_path='/path/to/chromedriver')\n",
    "\n",
    "# Open the Billboard Hot 100 page\n",
    "driver.get('https://www.billboard.com/charts/hot-100')\n",
    "\n",
    "# Allow the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Find the song elements\n",
    "songs = driver.find_elements(By.CSS_SELECTOR, 'li.o-chart-results-list__item')\n",
    "\n",
    "# List to hold the song details\n",
    "song_details = []\n",
    "\n",
    "# Loop through the songs to extract details\n",
    "for song in songs[:100]:  # Limit to top 100 songs\n",
    "    song_name = song.find_element(By.CSS_SELECTOR, 'h3.c-title.a-no-trucate').text.strip()\n",
    "    artist_name = song.find_element(By.CSS_SELECTOR, 'span.c-label.a-no-trucate').text.strip()\n",
    "    last_week_rank = song.find_element(By.CSS_SELECTOR, 'span.c-label.a-font-primary-bold-l').text.strip()\n",
    "    peak_rank = song.find_element(By.CSS_SELECTOR, 'span.c-label.a-font-primary-bold-s').text.strip()\n",
    "    weeks_on_board = song.find_element(By.CSS_SELECTOR, 'span.c-label.a-font-primary-bold-l').text.strip()\n",
    "    song_details.append([song_name, artist_name, last_week_rank, peak_rank, weeks_on_board])\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Print the details\n",
    "for detail in song_details:\n",
    "    print(detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a5e623",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scrape the details of Highest selling novels.\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    " Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18d434ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m cols \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m book_name \u001b[38;5;241m=\u001b[39m cols[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m---> 26\u001b[0m author_name \u001b[38;5;241m=\u001b[39m cols[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     27\u001b[0m volumes_sold \u001b[38;5;241m=\u001b[39m cols[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     28\u001b[0m publisher \u001b[38;5;241m=\u001b[39m cols[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the Guardian page\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "\n",
    "# Sending a request to the webpage\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parsing the content of the webpage\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Finding the table containing the highest selling novels\n",
    "table = soup.find('table', {'class': 'in-article sortable'})\n",
    "\n",
    "# Extracting the table rows\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "# List to hold the book details\n",
    "book_details = []\n",
    "\n",
    "# Looping through the rows to extract details\n",
    "for row in rows[1:]:  # Skipping the header row\n",
    "    cols = row.find_all('td')\n",
    "    book_name = cols[0].text.strip()\n",
    "    author_name = cols[1].text.strip()\n",
    "    volumes_sold = cols[2].text.strip()\n",
    "    publisher = cols[3].text.strip()\n",
    "    genre = cols[4].text.strip()\n",
    "    book_details.append([book_name, author_name, volumes_sold, publisher, genre])\n",
    "\n",
    "# Print the details\n",
    "for detail in book_details:\n",
    "    print(detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bce6dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have\n",
    "to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ac66f73",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m cols \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m book_name \u001b[38;5;241m=\u001b[39m cols[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m---> 26\u001b[0m author_name \u001b[38;5;241m=\u001b[39m cols[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     27\u001b[0m volumes_sold \u001b[38;5;241m=\u001b[39m cols[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     28\u001b[0m publisher \u001b[38;5;241m=\u001b[39m cols[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the Guardian page\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "\n",
    "# Sending a request to the webpage\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parsing the content of the webpage\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Finding the table containing the highest selling novels\n",
    "table = soup.find('table', {'class': 'in-article sortable'})\n",
    "\n",
    "# Extracting the table rows\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "# List to hold the book details\n",
    "book_details = []\n",
    "\n",
    "# Looping through the rows to extract details\n",
    "for row in rows[1:]:  # Skipping the header row\n",
    "    cols = row.find_all('td')\n",
    "    book_name = cols[0].text.strip()\n",
    "    author_name = cols[1].text.strip()\n",
    "    volumes_sold = cols[2].text.strip()\n",
    "    publisher = cols[3].text.strip()\n",
    "    genre = cols[4].text.strip()\n",
    "    book_details.append([book_name, author_name, volumes_sold, publisher, genre])\n",
    "\n",
    "# Print the details\n",
    "for detail in book_details:\n",
    "    print(detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068b4ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    " Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/ You\n",
    "have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5394277",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m By\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Set up the Selenium WebDriver\n",
    "driver = webdriver.Chrome(executable_path='/path/to/chromedriver')\n",
    "\n",
    "# Open the UCI Machine Learning Repository\n",
    "driver.get('https://archive.ics.uci.edu/')\n",
    "\n",
    "# Allow the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Navigate to the datasets section\n",
    "datasets_link = driver.find_element(By.LINK_TEXT, 'View ALL Data Sets').click()\n",
    "\n",
    "# Allow the datasets page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Find the dataset elements\n",
    "datasets = driver.find_elements(By.CSS_SELECTOR, 'table tbody tr')\n",
    "\n",
    "# List to hold the dataset details\n",
    "dataset_details = []\n",
    "\n",
    "# Loop through the datasets to extract details\n",
    "for dataset in datasets:\n",
    "    details = dataset.find_elements(By.TAG_NAME, 'td')\n",
    "    dataset_name = details[0].text.strip()\n",
    "    data_type = details[1].text.strip()\n",
    "    task = details[2].text.strip()\n",
    "    attribute_type = details[3].text.strip()\n",
    "    no_of_instances = details[4].text.strip()\n",
    "    no_of_attributes = details[5].text.strip()\n",
    "    year = details[6].text.strip()\n",
    "    dataset_details.append([dataset_name, data_type, task, attribute_type, no_of_instances, no_of_attributes, year])\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Print the details\n",
    "for detail in dataset_details:\n",
    "    print(detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605f71f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
